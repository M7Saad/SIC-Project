{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIC PROJECT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All requirements are installed\n"
     ]
    }
   ],
   "source": [
    "#requirements and dependencies\n",
    "#check if the requirements are installed\n",
    "requirements = [\"tensorflow\", \"numpy\", \"cv2\", \"tqdm\", \"matplotlib\", \"tensorboard\", \"tensorflow_hub\", \"sklearn\"]\n",
    "#if not, quit\n",
    "for requirement in requirements:\n",
    "    try:\n",
    "        __import__(requirement)\n",
    "    except ImportError:\n",
    "        print(\"You need to install the following package: \" + requirement)\n",
    "        print(\"You can do this by running: pip install \" + requirement)\n",
    "        quit()\n",
    "print(\"All requirements are installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 03:00:11.557497: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-31 03:00:11.557518: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check metal gpu\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data(path, IMG_SIZE=224):\n",
    "    \"\"\"\n",
    "    Load image data from directory, resize and normalize it.\n",
    "    return tuple `(images, labels)`.\n",
    "    \"\"\"\n",
    "    categories = os.listdir(path)\n",
    "    categories.remove('.DS_Store')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in tqdm.tqdm(categories):\n",
    "        folder_path = os.path.join(path, category)\n",
    "\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append(img)\n",
    "                labels.append(categories.index(category))\n",
    "\n",
    "    return np.array(data), tf.keras.utils.to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#built from scratch model\n",
    "def get_model(IMG_SIZE = 224, NUM_CLASSES = 3):\n",
    "    \n",
    "    #model architecture\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "       tf.keras.layers.Conv2D(\n",
    "           64, (3, 3), activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "       ),\n",
    "\n",
    "       tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "       tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "       tf.keras.layers.Conv2D(\n",
    "           128, (3, 3), activation=\"relu\"),\n",
    "\n",
    "       tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "       tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "       tf.keras.layers.Flatten(),\n",
    "\n",
    "       tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "\n",
    "       tf.keras.layers.Dropout(0.25),\n",
    "       ##\n",
    "\n",
    "       tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "\n",
    "    ])\n",
    "\n",
    "    # Compile Model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2699 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 03:03:48.984787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-31 03:03:51.264582: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_16/kernel/Assign' id:44172 op device:{requested: '', assigned: ''} def:{{{node conv2d_16/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_16/kernel, conv2d_16/kernel/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-31 03:03:57.316789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-31 03:04:01.416362: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/mohammed/miniconda3/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-07-31 03:04:03.668048: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_14/mul' id:44362 op device:{requested: '', assigned: ''} def:{{{node loss_14/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_14/mul/x, loss_14/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-31 03:04:10.410869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  32/2699 [..............................] - ETA: 14:52 - loss: 44.8403 - accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 03:04:14.401850: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-07-31 03:04:14.401872: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  64/2699 [..............................] - ETA: 7:53 - loss: 14315.8733 - accuracy: 0.3594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 03:04:15.137585: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-07-31 03:04:15.140991: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-07-31 03:04:15.143162: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs/fit/20230731-030335/plugins/profile/2023_07_31_03_04_15/Mohammeds-MBP.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2699/2699 [==============================] - 35s 13ms/sample - loss: 1081.9914 - accuracy: 0.3583\n"
     ]
    }
   ],
   "source": [
    "#load data \n",
    "train_data, train_labels = load_data('Train')\n",
    "test_data, test_labels = load_data('Test')\n",
    "\n",
    "#load model\n",
    "model = get_model()\n",
    "\n",
    "#some parameters\n",
    "EPOCHS = 1\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#for tensorboard\n",
    "log_dir = \"logs/fit/\" + str(len(os.listdir('logs/fit')))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,  histogram_freq=1)\n",
    "\n",
    "#train the model and validate the model #TODO: split the train data into train and validation, DON'T USE TEST DATA FOR VALIDATION*\n",
    "history = model.fit(train_data, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[tensorboard_callback])\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lunch tensorboard to plot the results and the graphs\n",
    "print(\"model accuracy: \" + str(test_acc))\n",
    "print(\"allah y3een\")\n",
    "%tensorboard --logdir=logs --port=6969"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
